"""
Example Usage of RAG Evaluation System

This script demonstrates how to use the RAG evaluation system
with sample data and shows the evaluation results.
"""

from .evaluation_runner import evaluate_rag_output, RAGEvaluator
from . import create_evaluation_input


def run_evaluation_examples():
    """Run example evaluations to demonstrate the system"""

    print("ğŸš€ RAG Evaluation System - Example Usage\n")

    # Example 1: Good RAG response
    print("ğŸ“ Example 1: High-quality RAG response")
    print("-" * 50)

    good_input = create_evaluation_input(
        question="LÃ m tháº¿ nÃ o Ä‘á»ƒ Ä‘Äƒng kÃ½ tÃ i khoáº£n trÃªn há»‡ thá»‘ng?",
        answer="Äá»ƒ Ä‘Äƒng kÃ½ tÃ i khoáº£n, báº¡n cáº§n:\n1. Truy cáº­p trang Ä‘Äƒng kÃ½ trÃªn website\n2. Äiá»n Ä‘áº§y Ä‘á»§ thÃ´ng tin cÃ¡ nhÃ¢n bao gá»“m há» tÃªn, email, vÃ  máº­t kháº©u\n3. XÃ¡c nháº­n Ä‘á»‹a chá»‰ email báº±ng cÃ¡ch nháº¥p vÃ o liÃªn káº¿t Ä‘Æ°á»£c gá»­i\n4. ÄÄƒng nháº­p báº±ng tÃ i khoáº£n má»›i táº¡o",
        context="HÆ°á»›ng dáº«n Ä‘Äƒng kÃ½ tÃ i khoáº£n:\n- Truy cáº­p website vÃ  nháº¥p 'ÄÄƒng kÃ½'\n- Äiá»n thÃ´ng tin: há» tÃªn, email, máº­t kháº©u\n- XÃ¡c nháº­n email Ä‘á»ƒ kÃ­ch hoáº¡t tÃ i khoáº£n\n- Sau khi kÃ­ch hoáº¡t, cÃ³ thá»ƒ Ä‘Äƒng nháº­p bÃ¬nh thÆ°á»ng",
        retrieved_docs=[
            {"page_content": "Quy trÃ¬nh Ä‘Äƒng kÃ½ tÃ i khoáº£n gá»“m 4 bÆ°á»›c chÃ­nh..."},
            {"page_content": "Há»‡ thá»‘ng yÃªu cáº§u xÃ¡c nháº­n email Ä‘á»ƒ báº£o máº­t..."}
        ]
    )

    results = evaluate_rag_output(
        question=good_input.question,
        answer=good_input.answer,
        context=good_input.context,
        retrieved_docs=good_input.retrieved_docs,
        methods=["faithfulness_llm", "relevance_llm", "completeness_llm", "groundedness_llm"]
    )

    print_evaluation_results(results)

    # Example 2: Poor RAG response
    print("\nğŸ“ Example 2: Low-quality RAG response")
    print("-" * 50)

    poor_input = create_evaluation_input(
        question="Chi phÃ­ cá»§a dá»‹ch vá»¥ premium lÃ  bao nhiÃªu?",
        answer="Dá»‹ch vá»¥ nÃ y ráº¥t tá»‘t vÃ  Ä‘Ã¡ng tin cáº­y.",
        context="Báº£ng giÃ¡ dá»‹ch vá»¥:\n- CÆ¡ báº£n: 50,000 VND/thÃ¡ng\n- Premium: 150,000 VND/thÃ¡ng\n- Enterprise: 500,000 VND/thÃ¡ng\nTáº¥t cáº£ giÃ¡ Ä‘Ã£ bao gá»“m VAT.",
        retrieved_docs=[
            {"page_content": "Chi tiáº¿t báº£ng giÃ¡ cÃ¡c gÃ³i dá»‹ch vá»¥..."}
        ]
    )

    results = evaluate_rag_output(
        question=poor_input.question,
        answer=poor_input.answer,
        context=poor_input.context,
        retrieved_docs=poor_input.retrieved_docs,
        methods=["faithfulness_llm", "relevance_llm", "completeness_llm", "groundedness_llm"]
    )

    print_evaluation_results(results)

    # Example 3: Comprehensive evaluation
    print("\nğŸ“Š Example 3: Full evaluation suite")
    print("-" * 50)

    comprehensive_evaluator = RAGEvaluator()
    full_results = comprehensive_evaluator.evaluate(good_input)

    print(f"Overall Score: {full_results['summary']['overall_score']:.3f}")
    print("\nDetailed Category Scores:")
    for category, data in full_results['summary']['category_scores'].items():
        print(f"  {category}: {data['score']:.3f} ({data['methods_used']}/{data['methods_available']} methods)")

    print(f"\nEvaluation completed in {full_results['metadata']['evaluation_time']:.2f} seconds")
    print(f"Methods run: {full_results['metadata']['methods_run']}")


def print_evaluation_results(results: dict):
    """Print evaluation results in a readable format"""
    print(f"Overall Score: {results['summary']['overall_score']:.3f}")

    print("\nCategory Breakdown:")
    for category, data in results['summary']['category_scores'].items():
        print(f"  {category}: {data['score']:.3f}")

    print(f"\nSuccessful evaluations: {results['metadata']['methods_run']}")
    print(f"Evaluation time: {results['metadata']['evaluation_time']:.2f} seconds")


def create_sample_evaluation_data():
    """Create sample data for testing different scenarios"""

    samples = [
        {
            "name": "Perfect Answer",
            "question": "Quy trÃ¬nh thanh toÃ¡n nhÆ° tháº¿ nÃ o?",
            "answer": "Quy trÃ¬nh thanh toÃ¡n gá»“m 3 bÆ°á»›c: 1) Chá»n sáº£n pháº©m, 2) Nháº­p thÃ´ng tin thanh toÃ¡n, 3) XÃ¡c nháº­n giao dá»‹ch.",
            "context": "Quy trÃ¬nh thanh toÃ¡n: Chá»n sáº£n pháº©m â†’ Nháº­p thÃ´ng tin tháº» â†’ XÃ¡c nháº­n â†’ HoÃ n táº¥t.",
            "expected_score": 0.9
        },
        {
            "name": "Incomplete Answer",
            "question": "LÃ m tháº¿ nÃ o Ä‘á»ƒ khÃ´i phá»¥c máº­t kháº©u?",
            "answer": "Báº¡n cÃ³ thá»ƒ khÃ´i phá»¥c máº­t kháº©u.",
            "context": "KhÃ´i phá»¥c máº­t kháº©u: Nháº¥p 'QuÃªn máº­t kháº©u' â†’ Nháº­p email â†’ Nháº­n mÃ£ OTP â†’ Äáº·t máº­t kháº©u má»›i.",
            "expected_score": 0.3
        },
        {
            "name": "Irrelevant Answer",
            "question": "Giá» lÃ m viá»‡c cá»§a há»— trá»£ khÃ¡ch hÃ ng?",
            "answer": "Sáº£n pháº©m cá»§a chÃºng tÃ´i cÃ³ nhiá»u mÃ u sáº¯c Ä‘áº¹p.",
            "context": "Há»— trá»£ khÃ¡ch hÃ ng: 8:00-18:00 tá»« thá»© 2 Ä‘áº¿n thá»© 6.",
            "expected_score": 0.1
        }
    ]

    return samples


if __name__ == "__main__":
    run_evaluation_examples()
